{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_station_train = pd.read_csv('Data/Train/X_station_train.csv')\n",
    "X_station_train['date'] = pd.to_datetime(X_station_train['date'])\n",
    "X_station_train['hour'] = X_station_train['date'].dt.hour\n",
    "# X_station_train['day'] = X_station_train['date'].dt.day\n",
    "X_station_train['month'] = X_station_train['date'].dt.month\n",
    "X_station_train[\"Id_h\"] = X_station_train[\"Id\"]\n",
    "X_station_train[\"Id\"] = X_station_train[\"Id\"].str.split(\"_\").apply(lambda s: s[:2]).str.join(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_forecast_train = pd.read_csv('Data/Train/Baselines/Baseline_forecast_train.csv')\n",
    "baseline_forecast_train = baseline_forecast_train.rename(columns=dict(Prediction=\"baseline_pred\"))\n",
    "baseline_observation_train = pd.read_csv('Data/Train/Baselines/Baseline_observation_train.csv')\n",
    "baseline_observation_train = baseline_observation_train.rename(columns=dict(Prediction=\"baseline_obs\"))\n",
    "station_coords = pd.read_csv('Data/Other/stations_coordinates.csv')\n",
    "Y_train = pd.read_csv('Data/Train/Y_train.csv')\n",
    "Y_train[\"date\"] = pd.to_datetime(Y_train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6899007"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_station_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_sta</th>\n",
       "      <th>date</th>\n",
       "      <th>ff</th>\n",
       "      <th>t</th>\n",
       "      <th>td</th>\n",
       "      <th>hu</th>\n",
       "      <th>dd</th>\n",
       "      <th>precip</th>\n",
       "      <th>Id</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>Id_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405628</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>275.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405629</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>275.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405630</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>275.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405631</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>2.71</td>\n",
       "      <td>276.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405632</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>2.72</td>\n",
       "      <td>276.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405633</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>276.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405634</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405635</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405636</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 08:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405637</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 09:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405638</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 10:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405639</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405640</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405641</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 13:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405642</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405643</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 15:00:00</td>\n",
       "      <td>8.60</td>\n",
       "      <td>282.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405644</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>9.26</td>\n",
       "      <td>282.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405645</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>8.65</td>\n",
       "      <td>281.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405646</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 18:00:00</td>\n",
       "      <td>8.41</td>\n",
       "      <td>281.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405647</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>7.33</td>\n",
       "      <td>282.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405648</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>284.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405649</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 21:00:00</td>\n",
       "      <td>7.36</td>\n",
       "      <td>284.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405650</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 22:00:00</td>\n",
       "      <td>7.86</td>\n",
       "      <td>284.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405651</th>\n",
       "      <td>22247002</td>\n",
       "      <td>2016-01-01 23:00:00</td>\n",
       "      <td>8.17</td>\n",
       "      <td>282.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22247002_0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>22247002_0_23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        number_sta                date    ff       t  td  hu     dd  precip  \\\n",
       "405628    22247002 2016-01-01 00:00:00  0.29  275.82 NaN NaN   54.0     0.0   \n",
       "405629    22247002 2016-01-01 01:00:00  0.61  275.23 NaN NaN  109.0     0.0   \n",
       "405630    22247002 2016-01-01 02:00:00  1.30  275.31 NaN NaN  120.0     0.0   \n",
       "405631    22247002 2016-01-01 03:00:00  2.71  276.09 NaN NaN  132.0     0.0   \n",
       "405632    22247002 2016-01-01 04:00:00  2.72  276.45 NaN NaN  135.0     0.0   \n",
       "405633    22247002 2016-01-01 05:00:00  2.80  276.55 NaN NaN  130.0     NaN   \n",
       "405634    22247002 2016-01-01 06:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405635    22247002 2016-01-01 07:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405636    22247002 2016-01-01 08:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405637    22247002 2016-01-01 09:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405638    22247002 2016-01-01 10:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405639    22247002 2016-01-01 11:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405640    22247002 2016-01-01 12:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405641    22247002 2016-01-01 13:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405642    22247002 2016-01-01 14:00:00   NaN     NaN NaN NaN    NaN     NaN   \n",
       "405643    22247002 2016-01-01 15:00:00  8.60  282.56 NaN NaN  157.0     0.0   \n",
       "405644    22247002 2016-01-01 16:00:00  9.26  282.25 NaN NaN  156.0     0.0   \n",
       "405645    22247002 2016-01-01 17:00:00  8.65  281.54 NaN NaN  152.0     0.0   \n",
       "405646    22247002 2016-01-01 18:00:00  8.41  281.84 NaN NaN  152.0     0.0   \n",
       "405647    22247002 2016-01-01 19:00:00  7.33  282.74 NaN NaN  164.0     0.0   \n",
       "405648    22247002 2016-01-01 20:00:00  7.69  284.22 NaN NaN  189.0     0.0   \n",
       "405649    22247002 2016-01-01 21:00:00  7.36  284.36 NaN NaN  190.0     0.0   \n",
       "405650    22247002 2016-01-01 22:00:00  7.86  284.00 NaN NaN  192.0     0.0   \n",
       "405651    22247002 2016-01-01 23:00:00  8.17  282.93 NaN NaN  190.0     0.2   \n",
       "\n",
       "                Id  hour  month           Id_h  \n",
       "405628  22247002_0     0      1   22247002_0_0  \n",
       "405629  22247002_0     1      1   22247002_0_1  \n",
       "405630  22247002_0     2      1   22247002_0_2  \n",
       "405631  22247002_0     3      1   22247002_0_3  \n",
       "405632  22247002_0     4      1   22247002_0_4  \n",
       "405633  22247002_0     5      1   22247002_0_5  \n",
       "405634  22247002_0     6      1   22247002_0_6  \n",
       "405635  22247002_0     7      1   22247002_0_7  \n",
       "405636  22247002_0     8      1   22247002_0_8  \n",
       "405637  22247002_0     9      1   22247002_0_9  \n",
       "405638  22247002_0    10      1  22247002_0_10  \n",
       "405639  22247002_0    11      1  22247002_0_11  \n",
       "405640  22247002_0    12      1  22247002_0_12  \n",
       "405641  22247002_0    13      1  22247002_0_13  \n",
       "405642  22247002_0    14      1  22247002_0_14  \n",
       "405643  22247002_0    15      1  22247002_0_15  \n",
       "405644  22247002_0    16      1  22247002_0_16  \n",
       "405645  22247002_0    17      1  22247002_0_17  \n",
       "405646  22247002_0    18      1  22247002_0_18  \n",
       "405647  22247002_0    19      1  22247002_0_19  \n",
       "405648  22247002_0    20      1  22247002_0_20  \n",
       "405649  22247002_0    21      1  22247002_0_21  \n",
       "405650  22247002_0    22      1  22247002_0_22  \n",
       "405651  22247002_0    23      1  22247002_0_23  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_id = baseline_observation_train.loc[baseline_observation_train[\"Prediction\"].isna(), \"Id\"]\n",
    "X_station_train[X_station_train[\"Id\"] == na_id.iloc[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_sta    0.000000\n",
       "date          0.000000\n",
       "ff            0.397058\n",
       "t             0.052390\n",
       "td            0.323928\n",
       "hu            0.323367\n",
       "dd            0.397474\n",
       "precip        0.070371\n",
       "Id            0.000000\n",
       "hour          0.000000\n",
       "month         0.000000\n",
       "Id_h          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_station_train.isna().sum() / len(X_station_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling... Done\n",
      "Imputing...Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "simple_imputer = SimpleImputer(strategy=\"median\")\n",
    "X_station_impute = X_station_train.copy()\n",
    "print(\"Scaling...\", end=\"\")\n",
    "X_station_impute[[\"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\"]] = scaler.fit_transform(X_station_impute[[\"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\"]])\n",
    "print(\" Done\")\n",
    "\n",
    "print(\"Imputing...\", end=\"\")\n",
    "X_station_impute[[\"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\"]] = simple_imputer.fit_transform(X_station_impute[[\"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\"]])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\envs\\defi-ia\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "C:\\Users\\aleks\\anaconda3\\envs\\defi-ia\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "baseline_scaler = StandardScaler()\n",
    "baseline_imputer = SimpleImputer(strategy=\"median\")\n",
    "baseline_observation_impute = baseline_observation_train[[\"Id\", \"baseline_obs\"]]\n",
    "baseline_observation_impute[[\"baseline_obs\"]] = baseline_scaler.fit_transform(baseline_observation_impute[[\"baseline_obs\"]])\n",
    "baseline_observation_impute[[\"baseline_obs\"]] = baseline_imputer.fit_transform(baseline_observation_impute[[\"baseline_obs\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_imputer = SimpleImputer(strategy=\"median\")\n",
    "y_impute = Y_train.copy()#[[\"Id\", \"number_sta\", \"Ground_truth\", \"Date\"]]\n",
    "y_impute[[\"Ground_truth\"]] = y_imputer.fit_transform(y_impute[[\"Ground_truth\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "Y_train = Y_train.sort_values([\"number_sta\", \"date\"]).reset_index(drop=True)\n",
    "X_station_train = X_station_train.sort_values([\"number_sta\", \"date\"]).reset_index(drop=True)\n",
    "station_numbers = Y_train[\"number_sta\"].unique()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "dataset = []\n",
    "for station_number in station_numbers:\n",
    "    y_station = Y_train[Y_train[\"number_sta\"] == station_number]\n",
    "    n_target = len(y_station)\n",
    "    if n_target < batch_size:\n",
    "        continue\n",
    "\n",
    "    X_station = X_station_train[X_station_train[\"number_sta\"] == station_number]\n",
    "    if len(y_station) != len(X_station) / 24:\n",
    "        temp_y = y_station[1:]\n",
    "        min_date = temp_y[\"date\"].min() - pd.Timedelta(\"1d\")\n",
    "        temp_X = X_station[X_station[\"date\"] >= min_date]\n",
    "        if len(temp_y) == len(temp_X) / 24:\n",
    "            y_station = temp_y\n",
    "            X_station = temp_X\n",
    "        else:\n",
    "            temp_y = y_station[:-1]\n",
    "            max_date = temp_y[\"date\"].max()\n",
    "            temp_X = X_station[X_station[\"date\"] < max_date]\n",
    "            if len(temp_y) == len(temp_X) / 24:\n",
    "                y_station = temp_y\n",
    "                X_station = temp_X\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "\n",
    "    if (X_station[\"date\"].diff()[1:] != pd.Timedelta(\"1h\")).any():\n",
    "        print(station_number)\n",
    "\n",
    "    cols = [\"Id\", \"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\"]\n",
    "    X = X_station.loc[X_station[\"hour\"] == 0, [\"month\"] + cols]\n",
    "    for h in range(1, 24):\n",
    "        X = pd.merge(X, X_station.loc[X_station[\"hour\"] == h, cols], on=\"Id\", suffixes=[\"\", f\"_{h}\"])\n",
    "    X = pd.merge(X, baseline_observation_train[[\"Id\", \"baseline_obs\"]], on=\"Id\", how=\"left\")\n",
    "    # X = pd.merge(X, baseline_observation_train[[\"Id\", \"baseline_obs\"]], on=\"Id\", how=\"left\")\n",
    "    X = X.drop(columns=\"Id\")\n",
    "    # X_station[\"day\"] = X_station[\"date\"].dt.day\n",
    "    # X = X_station[[\"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\", \"hour\", \"day\"]]\n",
    "    y = y_station[\"Ground_truth\"]\n",
    "    print(X.isna().sum().sum())\n",
    "    dataset.append((X, y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # min_date = y_station[\"date\"].min() - pd.Timedelta(\"1d\")\n",
    "    # max_date = y_station[\"date\"].max()\n",
    "    # X_station = X_station[X_station[\"date\"] >= min_date]\n",
    "    # X_station = X_station[X_station[\"date\"] < max_date]\n",
    "    # X_station = X_station_train[X_station_train[\"number_sta\"] == station_number]\n",
    "\n",
    "    # X_station = np.full((), fill_value=np.nan, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_impute = y_impute.sort_values([\"number_sta\", \"date\"]).reset_index(drop=True)\n",
    "X_station_impute = X_station_impute.sort_values([\"number_sta\", \"date\"]).reset_index(drop=True)\n",
    "station_numbers = y_impute[\"number_sta\"].unique()\n",
    "\n",
    "dataset = []\n",
    "\n",
    "X_ts = np.zeros((len(station_numbers), 729, 146))\n",
    "y_ts = np.zeros((len(station_numbers), 729))\n",
    "\n",
    "for station_number in station_numbers:\n",
    "    y_station = y_impute[y_impute[\"number_sta\"] == station_number]\n",
    "    n_target = len(y_station)\n",
    "    if n_target < batch_size:\n",
    "        continue\n",
    "\n",
    "    X_station = X_station_impute[X_station_impute[\"number_sta\"] == station_number]\n",
    "    if len(y_station) != len(X_station) / 24:\n",
    "        temp_y = y_station[1:]\n",
    "        min_date = temp_y[\"date\"].min() - pd.Timedelta(\"1d\")\n",
    "        temp_X = X_station[X_station[\"date\"] >= min_date]\n",
    "        if len(temp_y) == len(temp_X) / 24:\n",
    "            y_station = temp_y\n",
    "            X_station = temp_X\n",
    "        else:\n",
    "            temp_y = y_station[:-1]\n",
    "            max_date = temp_y[\"date\"].max()\n",
    "            temp_X = X_station[X_station[\"date\"] < max_date]\n",
    "            if len(temp_y) == len(temp_X) / 24:\n",
    "                y_station = temp_y\n",
    "                X_station = temp_X\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "\n",
    "    if (X_station[\"date\"].diff()[1:] != pd.Timedelta(\"1h\")).any():\n",
    "        print(station_number)\n",
    "\n",
    "    cols = [\"Id\", \"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\"]\n",
    "    X = X_station.loc[X_station[\"hour\"] == 0, [\"month\"] + cols]\n",
    "    for h in range(1, 24):\n",
    "        X = pd.merge(X, X_station.loc[X_station[\"hour\"] == h, cols], on=\"Id\", suffixes=[\"\", f\"_{h}\"])\n",
    "    X = pd.merge(X, baseline_observation_impute[[\"Id\", \"baseline_obs\"]], on=\"Id\", how=\"left\")\n",
    "    # X = pd.merge(X, baseline_observation_train[[\"Id\", \"baseline_obs\"]], on=\"Id\", how=\"left\")\n",
    "    X = X.drop(columns=\"Id\").iloc[:-1]\n",
    "    # X_station[\"day\"] = X_station[\"date\"].dt.day\n",
    "    # X = X_station[[\"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\", \"hour\", \"day\"]]\n",
    "    y = y_station[\"Ground_truth\"].iloc[:-1]\n",
    "    print(X.isna().sum().sum(), y.isna().sum())\n",
    "    dataset.append((X, y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # min_date = y_station[\"date\"].min() - pd.Timedelta(\"1d\")\n",
    "    # max_date = y_station[\"date\"].max()\n",
    "    # X_station = X_station[X_station[\"date\"] >= min_date]\n",
    "    # X_station = X_station[X_station[\"date\"] < max_date]\n",
    "    # X_station = X_station_train[X_station_train[\"number_sta\"] == station_number]\n",
    "\n",
    "    # X_station = np.full((), fill_value=np.nan, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_impute = y_impute.sort_values([\"number_sta\", \"date\"]).reset_index(drop=True)\n",
    "X_station_impute = X_station_impute.sort_values([\"number_sta\", \"date\"]).reset_index(drop=True)\n",
    "station_numbers = y_impute[\"number_sta\"].unique()\n",
    "\n",
    "X_ts = np.zeros((len(station_numbers), 24, 6))\n",
    "y_ts = np.zeros((len(station_numbers),))\n",
    "\n",
    "for i, station_number in enumerate(station_numbers):\n",
    "    y_station = y_impute[y_impute[\"number_sta\"] == station_number]\n",
    "    n_target = len(y_station)\n",
    "    if n_target < batch_size:\n",
    "        continue\n",
    "\n",
    "    X_station = X_station_impute[X_station_impute[\"number_sta\"] == station_number]\n",
    "\n",
    "    if (X_station[\"date\"].diff()[1:] != pd.Timedelta(\"1h\")).any():\n",
    "        print(station_number)\n",
    "\n",
    "    cols = [\"ff\", \"t\", \"td\", \"hu\", \"dd\", \"precip\"]\n",
    "\n",
    "    for h in range(24):\n",
    "        X_ts[i, h] = X_station.loc[X_station[\"hour\"] == h, cols]\n",
    "    y_ts[i,0] = y_station[\"Ground_truth\"]\n",
    "    y = y_station[\"Ground_truth\"].iloc[:-1]\n",
    "    print(X.isna().sum().sum(), y.isna().sum())\n",
    "    dataset.append((X, y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # min_date = y_station[\"date\"].min() - pd.Timedelta(\"1d\")\n",
    "    # max_date = y_station[\"date\"].max()\n",
    "    # X_station = X_station[X_station[\"date\"] >= min_date]\n",
    "    # X_station = X_station[X_station[\"date\"] < max_date]\n",
    "    # X_station = X_station_train[X_station_train[\"number_sta\"] == station_number]\n",
    "\n",
    "    # X_station = np.full((), fill_value=np.nan, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.60000000000002"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset)*.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import timeseries_dataset_from_array\n",
    "\n",
    "ts_train = timeseries_dataset_from_array(\n",
    "    X[:train_size], y[train_size],\n",
    "    sequence_length=14\n",
    ")\n",
    "\n",
    "ts_test = timeseries_dataset_from_array(\n",
    "    X[train_size], y[train_size],\n",
    "    sequence_length=14\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Input\n",
    "\n",
    "rnn_in = Input(shape=(14, 146))\n",
    "x = SimpleRNN(32, activation=\"tanh\")(rnn_in)\n",
    "rnn_out = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = Model(rnn_in, rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"mean_squared_logarithmic_error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19624/1725061775.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1118\u001b[0m       \u001b[1;31m# `Tensor` and `NumPy` input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       (x, y, sample_weight), validation_data = (\n\u001b[1;32m-> 1120\u001b[1;33m           data_adapter.train_validation_split(\n\u001b[0m\u001b[0;32m   1121\u001b[0m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m   1475\u001b[0m   \u001b[0munsplitable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_arrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_can_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1476\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0munsplitable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1477\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m   1478\u001b[0m         \u001b[1;34m\"`validation_split` is only supported for Tensors or NumPy \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m         \"arrays, found following types in the input: {}\".format(unsplitable))\n",
      "\u001b[1;31mValueError\u001b[0m: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>]"
     ]
    }
   ],
   "source": [
    "history = model.fit(ts, epochs=100, validation_split=.2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', 1)])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"a\":1}.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    for key, val in history.history.items():\n",
    "        plt.plot(val)\n",
    "        plt.title(key)\n",
    "        plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>number_sta</th>\n",
       "      <th>Ground_truth</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>14066001</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14066001_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>14066001</td>\n",
       "      <td>11.7</td>\n",
       "      <td>14066001_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.6</td>\n",
       "      <td>14066001_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>14066001_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>14066001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14066001_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>14066001</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14066001_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>14066001</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14066001_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>14066001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14066001_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>14066001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14066001_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>14066001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14066001_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>14066001</td>\n",
       "      <td>4.4</td>\n",
       "      <td>14066001_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>14066001</td>\n",
       "      <td>6.4</td>\n",
       "      <td>14066001_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>14066001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14066001_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14066001_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>14066001</td>\n",
       "      <td>5.2</td>\n",
       "      <td>14066001_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>14066001</td>\n",
       "      <td>1.2</td>\n",
       "      <td>14066001_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>14066001</td>\n",
       "      <td>8.3</td>\n",
       "      <td>14066001_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>14066001</td>\n",
       "      <td>12.9</td>\n",
       "      <td>14066001_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>14066001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14066001_29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  number_sta  Ground_truth           Id\n",
       "0  2016-01-02    14066001           3.4   14066001_0\n",
       "1  2016-01-03    14066001          11.7   14066001_1\n",
       "2  2016-01-04    14066001           0.6   14066001_2\n",
       "3  2016-01-05    14066001           0.4   14066001_3\n",
       "4  2016-01-06    14066001           3.0   14066001_4\n",
       "5  2016-01-07    14066001           7.0   14066001_5\n",
       "6  2016-01-08    14066001           0.0   14066001_6\n",
       "7  2016-01-09    14066001           9.5   14066001_7\n",
       "8  2016-01-10    14066001           1.0   14066001_8\n",
       "9  2016-01-11    14066001           6.0   14066001_9\n",
       "10 2016-01-12    14066001           1.0  14066001_10\n",
       "11 2016-01-13    14066001           0.0  14066001_11\n",
       "12 2016-01-14    14066001           4.4  14066001_12\n",
       "13 2016-01-15    14066001           6.4  14066001_13\n",
       "14 2016-01-16    14066001           1.0  14066001_14\n",
       "15 2016-01-17    14066001           0.0  14066001_15\n",
       "16 2016-01-18    14066001           0.0  14066001_16\n",
       "17 2016-01-19    14066001           0.0  14066001_17\n",
       "18 2016-01-20    14066001           0.2  14066001_18\n",
       "19 2016-01-21    14066001           0.0  14066001_19\n",
       "20 2016-01-22    14066001           5.2  14066001_20\n",
       "21 2016-01-23    14066001           1.2  14066001_21\n",
       "22 2016-01-24    14066001           0.0  14066001_22\n",
       "23 2016-01-25    14066001           0.0  14066001_23\n",
       "24 2016-01-26    14066001           0.0  14066001_24\n",
       "25 2016-01-27    14066001           8.3  14066001_25\n",
       "26 2016-01-28    14066001           0.0  14066001_26\n",
       "27 2016-01-29    14066001           0.0  14066001_27\n",
       "28 2016-01-30    14066001          12.9  14066001_28\n",
       "29 2016-01-31    14066001           0.0  14066001_29"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_impute.iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.4, shape=(), dtype=float64)\n",
      "tf.Tensor(1.4, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(4.9, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for (bx, by) in ts:\n",
    "    print(by[0])\n",
    "    # print(tf.math.is_nan(bx).any())\n",
    "    # print(model.predict(bx))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b46d4bff9394cddce87d03eb85a8fc6b48ee6ac0d1b6ddfc3a56b8e708fc43df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('defi-ia': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
